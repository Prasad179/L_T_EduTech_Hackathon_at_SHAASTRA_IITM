{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **L&T EduTech Hackathon at SHAASTRA IITM**\n\nHere we will try to find optimum training data in percentage with the help of pretrained model that we selected earlier. The judging metric is Cohen Kappa score. \n\n### Kappa Score:\nCohen’s kappa measures the agreement between two raters who each classify N items into C mutually exclusive categories.\n\nMore on Cohen kappa score can be found [here](https://towardsdatascience.com/cohens-kappa-9786ceceab58).","metadata":{"id":"w8NCbpMeV7Su"}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras import layers\nimport keras.backend as K\nfrom keras.models import Sequential, Model\nfrom keras.preprocessing import image\nfrom keras.layers import Input, Dense, Activation, Dropout\nfrom keras.layers import Flatten, BatchNormalization, Conv2D\nfrom keras.layers import MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D \nfrom keras.applications.imagenet_utils import preprocess_input\n\n\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom numpy import expand_dims\n\n!pip install opendatasets\nimport opendatasets as od","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lXMTdP4HVtdv","outputId":"50839f17-1a1e-469e-d41d-636f1257231b","execution":{"iopub.status.busy":"2023-01-17T04:04:03.694500Z","iopub.execute_input":"2023-01-17T04:04:03.694820Z","iopub.status.idle":"2023-01-17T04:04:21.429747Z","shell.execute_reply.started":"2023-01-17T04:04:03.694748Z","shell.execute_reply":"2023-01-17T04:04:21.428461Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting opendatasets\n  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from opendatasets) (8.1.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from opendatasets) (4.64.0)\nRequirement already satisfied: kaggle in /opt/conda/lib/python3.7/site-packages (from opendatasets) (1.5.12)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->opendatasets) (4.13.0)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (2.8.2)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (1.26.13)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (2.28.1)\nRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (1.15.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (2022.12.7)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.7/site-packages (from kaggle->opendatasets) (6.1.2)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->opendatasets) (4.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->opendatasets) (3.8.0)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.7/site-packages (from python-slugify->kaggle->opendatasets) (1.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle->opendatasets) (2.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle->opendatasets) (3.3)\nInstalling collected packages: opendatasets\nSuccessfully installed opendatasets-0.1.22\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"#od.download('https://www.kaggle.com/datasets/arpitjain007/game-of-deep-learning-ship-datasets/code')","metadata":{"id":"6GEF0RpsbJzq","execution":{"iopub.status.busy":"2023-01-17T04:04:21.432671Z","iopub.execute_input":"2023-01-17T04:04:21.434180Z","iopub.status.idle":"2023-01-17T04:04:21.439708Z","shell.execute_reply.started":"2023-01-17T04:04:21.434140Z","shell.execute_reply":"2023-01-17T04:04:21.438509Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"dataset_path = r'/kaggle/input/game-of-deep-learning-ship-datasets'  # main data folder path\ntrain_path = os.path.join(dataset_path, 'train')\nimages_path = os.path.join(train_path, 'images')\ntest_csv = os.path.join(dataset_path, 'test_ApKoW4T.csv')\ntrain_csv = os.path.join(train_path, 'train.csv')\n\ntest_df = pd.read_csv(test_csv)\ntrain_df = pd.read_csv(train_csv) # it contains image names and their respective labels\n\nnum_test_img = len(test_df)\nnum_train_img = len(train_df)\n\nprint(f'Total Number of test images: {num_test_img}')\nprint(f'Total Number of train images: {num_train_img}')","metadata":{"id":"bL2BcrsCbLZJ","execution":{"iopub.status.busy":"2023-01-17T04:04:21.443412Z","iopub.execute_input":"2023-01-17T04:04:21.444640Z","iopub.status.idle":"2023-01-17T04:04:21.485458Z","shell.execute_reply.started":"2023-01-17T04:04:21.444604Z","shell.execute_reply":"2023-01-17T04:04:21.484649Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Total Number of test images: 2680\nTotal Number of train images: 6252\n","output_type":"stream"}]},{"cell_type":"code","source":"main_path = \"/kaggle/input/game-of-deep-learning-ship-datasets/train/images/\"   # it contains all the images\nmain_df = pd.read_csv(r'/kaggle/input/game-of-deep-learning-ship-datasets/train/train.csv')\npaths = os.listdir(main_path)\nmain_df['path'] = main_path + main_df['image']    # In the path column, paths of all images saved.\n\ncategories = list(main_df['category'])   # Saves list of ship categories.\ncategorys = {1:'Cargo', 2:'Military', 3:'Carrier', 4:'Cruise', 5:'Tankers'}","metadata":{"id":"FLjWKnoWbP4B","execution":{"iopub.status.busy":"2023-01-17T04:04:21.491383Z","iopub.execute_input":"2023-01-17T04:04:21.493713Z","iopub.status.idle":"2023-01-17T04:04:21.822932Z","shell.execute_reply.started":"2023-01-17T04:04:21.493678Z","shell.execute_reply":"2023-01-17T04:04:21.822024Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"classes = []\nfor category in categories:\n    classes.append(categorys[category])         # Ship category is saved in classes sequencially.\n\n\nmain_df['classes'] = classes\ntest_df = pd.read_csv(r'/kaggle/input/game-of-deep-learning-ship-datasets/test_ApKoW4T.csv')\ntest_df['path'] = main_path + test_df['image']","metadata":{"id":"x9T7Oxayb1XR","execution":{"iopub.status.busy":"2023-01-17T04:04:21.824417Z","iopub.execute_input":"2023-01-17T04:04:21.824774Z","iopub.status.idle":"2023-01-17T04:04:21.836532Z","shell.execute_reply.started":"2023-01-17T04:04:21.824741Z","shell.execute_reply":"2023-01-17T04:04:21.835595Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"widths, heights = [], []\n\nfor path in tqdm(main_df[\"path\"]):\n    width, height = Image.open(path).size\n    widths.append(width)\n    heights.append(height)\n    \nmain_df[\"width\"] = widths\nmain_df[\"height\"] = heights\nmain_df[\"dimension\"] = main_df[\"width\"] * main_df[\"height\"]","metadata":{"id":"vrraLouOdizT","execution":{"iopub.status.busy":"2023-01-17T04:04:21.839325Z","iopub.execute_input":"2023-01-17T04:04:21.839670Z","iopub.status.idle":"2023-01-17T04:04:43.308300Z","shell.execute_reply.started":"2023-01-17T04:04:21.839635Z","shell.execute_reply":"2023-01-17T04:04:43.306908Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"100%|██████████| 6252/6252 [00:21<00:00, 291.53it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"X, y = main_df[['path', 'classes']], main_df['classes']\n\nX_data, X_test, y_data, y_test = train_test_split(X, y, test_size=0.1, random_state=42)  # 10% test and validation data\nX_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)  # 5% test data and 5% validation data","metadata":{"id":"VVpLzLrldvuA","execution":{"iopub.status.busy":"2023-01-17T04:04:43.312225Z","iopub.execute_input":"2023-01-17T04:04:43.312643Z","iopub.status.idle":"2023-01-17T04:04:43.334309Z","shell.execute_reply.started":"2023-01-17T04:04:43.312613Z","shell.execute_reply":"2023-01-17T04:04:43.333088Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(rotation_range=20,\n    zoom_range=0.10,\n    brightness_range=[0.6,1.4],\n    channel_shift_range=0.7,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode='nearest'\n) \n\nval_generator = datagen.flow_from_dataframe(\n        X_val,  # This is the source directory for training images\n        x_col='path',\n        y_col='classes',\n        target_size=(224, 224),  # All images will be resized to 150x150\n        batch_size=32,\n        class_mode=\"categorical\",\n        shuffle=True,\n)\ntest_generator = datagen.flow_from_dataframe(\n        X_test,  # This is the source directory for training images\n        x_col='path',\n        y_col='classes',\n        target_size=(224, 224),  # All images will be resized to 150x150\n        batch_size=32,\n        class_mode=\"categorical\",\n        shuffle=False,\n)","metadata":{"id":"Os2lAQ05iLdx","execution":{"iopub.status.busy":"2023-01-17T04:04:43.339564Z","iopub.execute_input":"2023-01-17T04:04:43.339990Z","iopub.status.idle":"2023-01-17T04:04:43.911159Z","shell.execute_reply.started":"2023-01-17T04:04:43.339957Z","shell.execute_reply":"2023-01-17T04:04:43.910118Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Found 313 validated image filenames belonging to 5 classes.\nFound 313 validated image filenames belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.applications.xception import Xception\nfrom sklearn.metrics import f1_score\nfrom sklearn import metrics\nfrom sklearn.metrics import cohen_kappa_score\nIMG_SHAPE = (224,224,3)\nxception_model = Xception(include_top=False, weights='imagenet', input_shape=IMG_SHAPE)","metadata":{"id":"D29BKCqLiLgx","execution":{"iopub.status.busy":"2023-01-17T04:04:43.912622Z","iopub.execute_input":"2023-01-17T04:04:43.912997Z","iopub.status.idle":"2023-01-17T04:04:50.442666Z","shell.execute_reply.started":"2023-01-17T04:04:43.912951Z","shell.execute_reply":"2023-01-17T04:04:50.441628Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2023-01-17 04:04:44.020596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 04:04:44.111266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 04:04:44.112090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 04:04:44.113329: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-01-17 04:04:44.113644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 04:04:44.114362: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 04:04:44.115031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 04:04:46.240997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 04:04:46.241824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 04:04:46.242548: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 04:04:46.243168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n83689472/83683744 [==============================] - 3s 0us/step\n83697664/83683744 [==============================] - 3s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"test_size1 = [0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1]\nfrom keras.models import load_model\n\nkappa_score = {}\nsaved_models = ['model10.h5','model20.h5','model30.h5','model40.h5','model50.h5','model60.h5','model70.h5','model80.h5']\nX_train = {}\nX_v = {}\ny_train= {}\ny_v = {}\nfor i in range(len(test_size1)):\n    X_train[i], X_v[i], y_train[i], y_v[i] = train_test_split(X_data, y_data, test_size= test_size1[i]/0.9, random_state=42)\n  \n    train_generator = datagen.flow_from_dataframe(\n        X_train[i],  # This is the source directory for training images\n        x_col='path',\n        y_col='classes',\n        target_size=(224, 224),  # All images will be resized to 224x224\n        batch_size=32,\n        class_mode=\"categorical\",\n        shuffle=True,\n        )\n\n    model_xception = tf.keras.Sequential([\n    xception_model,\n    tf.keras.layers.Conv2D(128, 3, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(5, activation='softmax')\n  ])\n\n    model_xception.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n              loss='categorical_crossentropy', \n              metrics=['accuracy'])\n\n    history_xception = model_xception.fit(\n      train_generator,\n      validation_data=val_generator,\n      epochs=20,\n      verbose=2)\n\n    model_xception.save(saved_models[i])\n\n    y_pred = model_xception.predict(test_generator)\n\n    y_pred_classes = np.argmax(y_pred, axis = 1)\n    print(\"\\nAccuracy:\",metrics.accuracy_score(test_generator.labels, y_pred_classes))\n    print('\\nF1 Score is',f1_score(test_generator.labels, y_pred_classes, average='weighted'))\n    kappa_score[i] = cohen_kappa_score(test_generator.labels, y_pred_classes)\n    print('\\nCohen Kappa Score is\\n ',kappa_score[i])","metadata":{"id":"V8sT9ax6iHQS","execution":{"iopub.status.busy":"2023-01-17T04:04:50.445929Z","iopub.execute_input":"2023-01-17T04:04:50.446307Z","iopub.status.idle":"2023-01-17T06:30:27.060232Z","shell.execute_reply.started":"2023-01-17T04:04:50.446265Z","shell.execute_reply":"2023-01-17T06:30:27.059062Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Found 625 validated image filenames belonging to 5 classes.\n","output_type":"stream"},{"name":"stderr","text":"2023-01-17 04:04:51.578741: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"2023-01-17 04:04:57.070079: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"20/20 - 28s - loss: 1.1096 - accuracy: 0.5616 - val_loss: 1.8114 - val_accuracy: 0.4185\nEpoch 2/20\n20/20 - 15s - loss: 0.5060 - accuracy: 0.8032 - val_loss: 2.0576 - val_accuracy: 0.5335\nEpoch 3/20\n20/20 - 16s - loss: 0.2653 - accuracy: 0.9088 - val_loss: 1.2347 - val_accuracy: 0.6550\nEpoch 4/20\n20/20 - 16s - loss: 0.1378 - accuracy: 0.9568 - val_loss: 1.1563 - val_accuracy: 0.7508\nEpoch 5/20\n20/20 - 15s - loss: 0.1163 - accuracy: 0.9584 - val_loss: 1.3097 - val_accuracy: 0.7636\nEpoch 6/20\n20/20 - 16s - loss: 0.1580 - accuracy: 0.9360 - val_loss: 0.8252 - val_accuracy: 0.8147\nEpoch 7/20\n20/20 - 15s - loss: 0.0992 - accuracy: 0.9648 - val_loss: 0.8002 - val_accuracy: 0.8466\nEpoch 8/20\n20/20 - 16s - loss: 0.0519 - accuracy: 0.9840 - val_loss: 0.6927 - val_accuracy: 0.8658\nEpoch 9/20\n20/20 - 15s - loss: 0.0350 - accuracy: 0.9904 - val_loss: 0.8621 - val_accuracy: 0.8307\nEpoch 10/20\n20/20 - 16s - loss: 0.0419 - accuracy: 0.9824 - val_loss: 0.8215 - val_accuracy: 0.8371\nEpoch 11/20\n20/20 - 15s - loss: 0.0400 - accuracy: 0.9888 - val_loss: 0.7523 - val_accuracy: 0.8594\nEpoch 12/20\n20/20 - 16s - loss: 0.0293 - accuracy: 0.9920 - val_loss: 0.6801 - val_accuracy: 0.8562\nEpoch 13/20\n20/20 - 15s - loss: 0.0241 - accuracy: 0.9904 - val_loss: 1.0447 - val_accuracy: 0.8115\nEpoch 14/20\n20/20 - 16s - loss: 0.0491 - accuracy: 0.9840 - val_loss: 0.7427 - val_accuracy: 0.8498\nEpoch 15/20\n20/20 - 15s - loss: 0.0597 - accuracy: 0.9776 - val_loss: 0.6948 - val_accuracy: 0.8466\nEpoch 16/20\n20/20 - 16s - loss: 0.0352 - accuracy: 0.9904 - val_loss: 0.6558 - val_accuracy: 0.8626\nEpoch 17/20\n20/20 - 15s - loss: 0.0508 - accuracy: 0.9840 - val_loss: 0.8452 - val_accuracy: 0.8498\nEpoch 18/20\n20/20 - 16s - loss: 0.0407 - accuracy: 0.9904 - val_loss: 0.6492 - val_accuracy: 0.8371\nEpoch 19/20\n20/20 - 15s - loss: 0.0244 - accuracy: 0.9936 - val_loss: 0.7556 - val_accuracy: 0.8466\nEpoch 20/20\n20/20 - 16s - loss: 0.0391 - accuracy: 0.9872 - val_loss: 0.6421 - val_accuracy: 0.8435\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n  category=CustomMaskWarning)\n","output_type":"stream"},{"name":"stdout","text":"\nAccuracy: 0.8849840255591054\n\nF1 Score is 0.8839664203084161\n\nCohen Kappa Score is\n  0.8522462038761113\nFound 1250 validated image filenames belonging to 5 classes.\nEpoch 1/20\n40/40 - 31s - loss: 0.3539 - accuracy: 0.8824 - val_loss: 0.3738 - val_accuracy: 0.8754\nEpoch 2/20\n40/40 - 26s - loss: 0.2039 - accuracy: 0.9272 - val_loss: 0.5444 - val_accuracy: 0.8371\nEpoch 3/20\n40/40 - 27s - loss: 0.1164 - accuracy: 0.9672 - val_loss: 0.4967 - val_accuracy: 0.8850\nEpoch 4/20\n40/40 - 26s - loss: 0.0533 - accuracy: 0.9832 - val_loss: 0.6153 - val_accuracy: 0.8818\nEpoch 5/20\n40/40 - 26s - loss: 0.1148 - accuracy: 0.9696 - val_loss: 0.3935 - val_accuracy: 0.8658\nEpoch 6/20\n40/40 - 26s - loss: 0.0593 - accuracy: 0.9832 - val_loss: 0.4680 - val_accuracy: 0.8594\nEpoch 7/20\n40/40 - 26s - loss: 0.1066 - accuracy: 0.9608 - val_loss: 0.7358 - val_accuracy: 0.8466\nEpoch 8/20\n40/40 - 26s - loss: 0.0448 - accuracy: 0.9864 - val_loss: 0.6614 - val_accuracy: 0.8786\nEpoch 9/20\n40/40 - 26s - loss: 0.0401 - accuracy: 0.9872 - val_loss: 0.6132 - val_accuracy: 0.8658\nEpoch 10/20\n40/40 - 26s - loss: 0.0615 - accuracy: 0.9800 - val_loss: 0.7614 - val_accuracy: 0.8147\nEpoch 11/20\n40/40 - 26s - loss: 0.0501 - accuracy: 0.9856 - val_loss: 0.5788 - val_accuracy: 0.8882\nEpoch 12/20\n40/40 - 26s - loss: 0.0621 - accuracy: 0.9808 - val_loss: 0.4801 - val_accuracy: 0.8882\nEpoch 13/20\n40/40 - 27s - loss: 0.0314 - accuracy: 0.9880 - val_loss: 0.4752 - val_accuracy: 0.8914\nEpoch 14/20\n40/40 - 26s - loss: 0.0277 - accuracy: 0.9920 - val_loss: 0.5761 - val_accuracy: 0.8690\nEpoch 15/20\n40/40 - 26s - loss: 0.0262 - accuracy: 0.9920 - val_loss: 0.4851 - val_accuracy: 0.9042\nEpoch 16/20\n40/40 - 26s - loss: 0.0195 - accuracy: 0.9952 - val_loss: 0.5435 - val_accuracy: 0.8882\nEpoch 17/20\n40/40 - 26s - loss: 0.0475 - accuracy: 0.9864 - val_loss: 0.6171 - val_accuracy: 0.8626\nEpoch 18/20\n40/40 - 26s - loss: 0.0277 - accuracy: 0.9928 - val_loss: 0.5062 - val_accuracy: 0.8882\nEpoch 19/20\n40/40 - 26s - loss: 0.0288 - accuracy: 0.9880 - val_loss: 0.5406 - val_accuracy: 0.8914\nEpoch 20/20\n40/40 - 26s - loss: 0.0230 - accuracy: 0.9944 - val_loss: 0.6778 - val_accuracy: 0.8882\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n  category=CustomMaskWarning)\n","output_type":"stream"},{"name":"stdout","text":"\nAccuracy: 0.8977635782747604\n\nF1 Score is 0.8976972959646603\n\nCohen Kappa Score is\n  0.8690650491528968\nFound 1875 validated image filenames belonging to 5 classes.\nEpoch 1/20\n59/59 - 43s - loss: 0.1997 - accuracy: 0.9392 - val_loss: 0.3846 - val_accuracy: 0.9010\nEpoch 2/20\n59/59 - 36s - loss: 0.0842 - accuracy: 0.9755 - val_loss: 0.4504 - val_accuracy: 0.8914\nEpoch 3/20\n59/59 - 37s - loss: 0.0675 - accuracy: 0.9765 - val_loss: 0.4516 - val_accuracy: 0.8882\nEpoch 4/20\n59/59 - 37s - loss: 0.0491 - accuracy: 0.9835 - val_loss: 0.3782 - val_accuracy: 0.8946\nEpoch 5/20\n59/59 - 37s - loss: 0.0664 - accuracy: 0.9819 - val_loss: 0.5166 - val_accuracy: 0.8786\nEpoch 6/20\n59/59 - 36s - loss: 0.0377 - accuracy: 0.9904 - val_loss: 0.7024 - val_accuracy: 0.8307\nEpoch 7/20\n59/59 - 37s - loss: 0.0180 - accuracy: 0.9920 - val_loss: 0.4111 - val_accuracy: 0.9010\nEpoch 8/20\n59/59 - 37s - loss: 0.0372 - accuracy: 0.9909 - val_loss: 0.4280 - val_accuracy: 0.8946\nEpoch 9/20\n59/59 - 38s - loss: 0.0280 - accuracy: 0.9909 - val_loss: 0.4808 - val_accuracy: 0.8946\nEpoch 10/20\n59/59 - 37s - loss: 0.0241 - accuracy: 0.9915 - val_loss: 0.5181 - val_accuracy: 0.8914\nEpoch 11/20\n59/59 - 37s - loss: 0.0299 - accuracy: 0.9915 - val_loss: 0.4781 - val_accuracy: 0.8946\nEpoch 12/20\n59/59 - 37s - loss: 0.0206 - accuracy: 0.9920 - val_loss: 0.5886 - val_accuracy: 0.8882\nEpoch 13/20\n59/59 - 37s - loss: 0.0329 - accuracy: 0.9920 - val_loss: 0.5398 - val_accuracy: 0.9073\nEpoch 14/20\n59/59 - 37s - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.5482 - val_accuracy: 0.8946\nEpoch 15/20\n59/59 - 37s - loss: 0.0194 - accuracy: 0.9952 - val_loss: 0.5689 - val_accuracy: 0.8850\nEpoch 16/20\n59/59 - 37s - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.6363 - val_accuracy: 0.9010\nEpoch 17/20\n59/59 - 37s - loss: 0.0222 - accuracy: 0.9925 - val_loss: 0.8287 - val_accuracy: 0.8690\nEpoch 18/20\n59/59 - 37s - loss: 0.0173 - accuracy: 0.9941 - val_loss: 0.6219 - val_accuracy: 0.8978\nEpoch 19/20\n59/59 - 37s - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.5500 - val_accuracy: 0.8914\nEpoch 20/20\n59/59 - 37s - loss: 0.0116 - accuracy: 0.9947 - val_loss: 0.4984 - val_accuracy: 0.9042\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n  category=CustomMaskWarning)\n","output_type":"stream"},{"name":"stdout","text":"\nAccuracy: 0.952076677316294\n\nF1 Score is 0.9519203704976885\n\nCohen Kappa Score is\n  0.9382529328212952\nFound 2500 validated image filenames belonging to 5 classes.\nEpoch 1/20\n79/79 - 53s - loss: 0.1410 - accuracy: 0.9632 - val_loss: 0.2846 - val_accuracy: 0.9201\nEpoch 2/20\n79/79 - 47s - loss: 0.0571 - accuracy: 0.9856 - val_loss: 0.4492 - val_accuracy: 0.8850\nEpoch 3/20\n79/79 - 47s - loss: 0.0432 - accuracy: 0.9888 - val_loss: 0.3502 - val_accuracy: 0.9042\nEpoch 4/20\n79/79 - 47s - loss: 0.0512 - accuracy: 0.9876 - val_loss: 0.5407 - val_accuracy: 0.8818\nEpoch 5/20\n79/79 - 48s - loss: 0.0217 - accuracy: 0.9936 - val_loss: 0.5405 - val_accuracy: 0.8978\nEpoch 6/20\n79/79 - 47s - loss: 0.0353 - accuracy: 0.9904 - val_loss: 0.4872 - val_accuracy: 0.8882\nEpoch 7/20\n79/79 - 47s - loss: 0.0368 - accuracy: 0.9896 - val_loss: 0.4231 - val_accuracy: 0.8978\nEpoch 8/20\n79/79 - 48s - loss: 0.0144 - accuracy: 0.9944 - val_loss: 0.4882 - val_accuracy: 0.8914\nEpoch 9/20\n79/79 - 47s - loss: 0.0273 - accuracy: 0.9928 - val_loss: 0.4762 - val_accuracy: 0.8914\nEpoch 10/20\n79/79 - 47s - loss: 0.0168 - accuracy: 0.9956 - val_loss: 0.3718 - val_accuracy: 0.9201\nEpoch 11/20\n79/79 - 47s - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.6032 - val_accuracy: 0.8818\nEpoch 12/20\n79/79 - 47s - loss: 0.0232 - accuracy: 0.9964 - val_loss: 0.4410 - val_accuracy: 0.8850\nEpoch 13/20\n79/79 - 47s - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.4368 - val_accuracy: 0.9073\nEpoch 14/20\n79/79 - 47s - loss: 0.0249 - accuracy: 0.9928 - val_loss: 0.6363 - val_accuracy: 0.8914\nEpoch 15/20\n79/79 - 47s - loss: 0.0482 - accuracy: 0.9856 - val_loss: 0.3855 - val_accuracy: 0.9137\nEpoch 16/20\n79/79 - 48s - loss: 0.0266 - accuracy: 0.9928 - val_loss: 0.3919 - val_accuracy: 0.9010\nEpoch 17/20\n79/79 - 47s - loss: 0.0350 - accuracy: 0.9872 - val_loss: 0.3553 - val_accuracy: 0.9010\nEpoch 18/20\n79/79 - 48s - loss: 0.0371 - accuracy: 0.9884 - val_loss: 0.4978 - val_accuracy: 0.9010\nEpoch 19/20\n79/79 - 47s - loss: 0.0249 - accuracy: 0.9936 - val_loss: 0.4880 - val_accuracy: 0.9042\nEpoch 20/20\n79/79 - 48s - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.6071 - val_accuracy: 0.8882\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n  category=CustomMaskWarning)\n","output_type":"stream"},{"name":"stdout","text":"\nAccuracy: 0.9424920127795527\n\nF1 Score is 0.9420656040039451\n\nCohen Kappa Score is\n  0.9258918236346417\nFound 3125 validated image filenames belonging to 5 classes.\nEpoch 1/20\n98/98 - 63s - loss: 0.1081 - accuracy: 0.9734 - val_loss: 0.3680 - val_accuracy: 0.9073\nEpoch 2/20\n98/98 - 58s - loss: 0.0455 - accuracy: 0.9875 - val_loss: 0.5443 - val_accuracy: 0.9010\nEpoch 3/20\n98/98 - 58s - loss: 0.0286 - accuracy: 0.9907 - val_loss: 0.4788 - val_accuracy: 0.9233\nEpoch 4/20\n98/98 - 58s - loss: 0.0273 - accuracy: 0.9942 - val_loss: 0.4281 - val_accuracy: 0.9105\nEpoch 5/20\n98/98 - 58s - loss: 0.0217 - accuracy: 0.9926 - val_loss: 0.4318 - val_accuracy: 0.9233\nEpoch 6/20\n98/98 - 58s - loss: 0.0325 - accuracy: 0.9898 - val_loss: 0.3698 - val_accuracy: 0.8914\nEpoch 7/20\n98/98 - 58s - loss: 0.0249 - accuracy: 0.9949 - val_loss: 0.4598 - val_accuracy: 0.9010\nEpoch 8/20\n98/98 - 58s - loss: 0.0263 - accuracy: 0.9933 - val_loss: 0.5978 - val_accuracy: 0.9010\nEpoch 9/20\n98/98 - 58s - loss: 0.0236 - accuracy: 0.9946 - val_loss: 0.4783 - val_accuracy: 0.9105\nEpoch 10/20\n98/98 - 57s - loss: 0.0068 - accuracy: 0.9968 - val_loss: 0.5357 - val_accuracy: 0.9137\nEpoch 11/20\n98/98 - 58s - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.5206 - val_accuracy: 0.9010\nEpoch 12/20\n98/98 - 59s - loss: 0.0192 - accuracy: 0.9946 - val_loss: 0.4384 - val_accuracy: 0.9137\nEpoch 13/20\n98/98 - 60s - loss: 0.0112 - accuracy: 0.9958 - val_loss: 0.4555 - val_accuracy: 0.9042\nEpoch 14/20\n98/98 - 58s - loss: 0.0162 - accuracy: 0.9962 - val_loss: 0.5250 - val_accuracy: 0.9105\nEpoch 15/20\n98/98 - 57s - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.3388 - val_accuracy: 0.9361\nEpoch 16/20\n98/98 - 57s - loss: 0.0362 - accuracy: 0.9910 - val_loss: 0.5151 - val_accuracy: 0.9010\nEpoch 17/20\n98/98 - 57s - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.5020 - val_accuracy: 0.8978\nEpoch 18/20\n98/98 - 58s - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.5283 - val_accuracy: 0.9201\nEpoch 19/20\n98/98 - 58s - loss: 0.0226 - accuracy: 0.9952 - val_loss: 0.3284 - val_accuracy: 0.9265\nEpoch 20/20\n98/98 - 58s - loss: 0.0150 - accuracy: 0.9962 - val_loss: 0.4561 - val_accuracy: 0.9137\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n  category=CustomMaskWarning)\n","output_type":"stream"},{"name":"stdout","text":"\nAccuracy: 0.9329073482428115\n\nF1 Score is 0.9325680494613631\n\nCohen Kappa Score is\n  0.9136199963203406\nFound 3750 validated image filenames belonging to 5 classes.\nEpoch 1/20\n118/118 - 74s - loss: 0.0827 - accuracy: 0.9773 - val_loss: 0.2656 - val_accuracy: 0.9169\nEpoch 2/20\n118/118 - 68s - loss: 0.0355 - accuracy: 0.9901 - val_loss: 0.3190 - val_accuracy: 0.9137\nEpoch 3/20\n118/118 - 68s - loss: 0.0294 - accuracy: 0.9928 - val_loss: 0.2821 - val_accuracy: 0.9105\nEpoch 4/20\n118/118 - 69s - loss: 0.0225 - accuracy: 0.9939 - val_loss: 0.4068 - val_accuracy: 0.9265\nEpoch 5/20\n118/118 - 68s - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.3469 - val_accuracy: 0.9297\nEpoch 6/20\n118/118 - 68s - loss: 0.0245 - accuracy: 0.9941 - val_loss: 0.3530 - val_accuracy: 0.9201\nEpoch 7/20\n118/118 - 68s - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.2882 - val_accuracy: 0.9265\nEpoch 8/20\n118/118 - 70s - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.2668 - val_accuracy: 0.9361\nEpoch 9/20\n118/118 - 68s - loss: 0.0185 - accuracy: 0.9955 - val_loss: 0.3849 - val_accuracy: 0.9265\nEpoch 10/20\n118/118 - 69s - loss: 0.0175 - accuracy: 0.9968 - val_loss: 0.4079 - val_accuracy: 0.9105\nEpoch 11/20\n118/118 - 68s - loss: 0.0301 - accuracy: 0.9941 - val_loss: 0.3673 - val_accuracy: 0.9073\nEpoch 12/20\n118/118 - 68s - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.3715 - val_accuracy: 0.9105\nEpoch 13/20\n118/118 - 68s - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.3452 - val_accuracy: 0.9233\nEpoch 14/20\n118/118 - 68s - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.4356 - val_accuracy: 0.9105\nEpoch 15/20\n118/118 - 69s - loss: 0.0240 - accuracy: 0.9963 - val_loss: 0.5984 - val_accuracy: 0.9169\nEpoch 16/20\n118/118 - 69s - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.6696 - val_accuracy: 0.9201\nEpoch 17/20\n118/118 - 68s - loss: 0.0190 - accuracy: 0.9947 - val_loss: 0.7706 - val_accuracy: 0.9105\nEpoch 18/20\n118/118 - 69s - loss: 0.0263 - accuracy: 0.9955 - val_loss: 0.4217 - val_accuracy: 0.9233\nEpoch 19/20\n118/118 - 68s - loss: 0.0128 - accuracy: 0.9965 - val_loss: 0.4699 - val_accuracy: 0.9233\nEpoch 20/20\n118/118 - 68s - loss: 0.0171 - accuracy: 0.9963 - val_loss: 0.4765 - val_accuracy: 0.9169\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n  category=CustomMaskWarning)\n","output_type":"stream"},{"name":"stdout","text":"\nAccuracy: 0.9552715654952076\n\nF1 Score is 0.9548044899550644\n\nCohen Kappa Score is\n  0.942345139729488\nFound 4375 validated image filenames belonging to 5 classes.\nEpoch 1/20\n137/137 - 84s - loss: 0.0747 - accuracy: 0.9845 - val_loss: 0.4184 - val_accuracy: 0.9010\nEpoch 2/20\n137/137 - 80s - loss: 0.0226 - accuracy: 0.9938 - val_loss: 0.2337 - val_accuracy: 0.9297\nEpoch 3/20\n137/137 - 78s - loss: 0.0175 - accuracy: 0.9959 - val_loss: 0.3742 - val_accuracy: 0.9201\nEpoch 4/20\n137/137 - 78s - loss: 0.0207 - accuracy: 0.9943 - val_loss: 0.3543 - val_accuracy: 0.9233\nEpoch 5/20\n137/137 - 78s - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.3111 - val_accuracy: 0.9329\nEpoch 6/20\n137/137 - 79s - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.3604 - val_accuracy: 0.9169\nEpoch 7/20\n137/137 - 78s - loss: 0.0139 - accuracy: 0.9968 - val_loss: 0.4621 - val_accuracy: 0.9073\nEpoch 8/20\n137/137 - 79s - loss: 0.0168 - accuracy: 0.9952 - val_loss: 0.6740 - val_accuracy: 0.8850\nEpoch 9/20\n137/137 - 79s - loss: 0.0205 - accuracy: 0.9947 - val_loss: 0.5643 - val_accuracy: 0.9297\nEpoch 10/20\n137/137 - 79s - loss: 0.0125 - accuracy: 0.9975 - val_loss: 0.4533 - val_accuracy: 0.9010\nEpoch 11/20\n137/137 - 79s - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.5818 - val_accuracy: 0.9169\nEpoch 12/20\n137/137 - 79s - loss: 0.0106 - accuracy: 0.9977 - val_loss: 0.5129 - val_accuracy: 0.9233\nEpoch 13/20\n137/137 - 78s - loss: 0.0173 - accuracy: 0.9957 - val_loss: 0.4561 - val_accuracy: 0.9265\nEpoch 14/20\n137/137 - 78s - loss: 0.0185 - accuracy: 0.9959 - val_loss: 0.4586 - val_accuracy: 0.9169\nEpoch 15/20\n137/137 - 79s - loss: 0.0097 - accuracy: 0.9977 - val_loss: 0.5789 - val_accuracy: 0.9137\nEpoch 16/20\n137/137 - 79s - loss: 0.0277 - accuracy: 0.9920 - val_loss: 0.4256 - val_accuracy: 0.9201\nEpoch 17/20\n137/137 - 79s - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.4318 - val_accuracy: 0.9233\nEpoch 18/20\n137/137 - 79s - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.5514 - val_accuracy: 0.9137\nEpoch 19/20\n137/137 - 79s - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.4410 - val_accuracy: 0.9297\nEpoch 20/20\n137/137 - 79s - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.7438 - val_accuracy: 0.9105\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n  category=CustomMaskWarning)\n","output_type":"stream"},{"name":"stdout","text":"\nAccuracy: 0.9584664536741214\n\nF1 Score is 0.9582392717675204\n\nCohen Kappa Score is\n  0.9465041676527044\nFound 5000 validated image filenames belonging to 5 classes.\nEpoch 1/20\n157/157 - 95s - loss: 0.0708 - accuracy: 0.9854 - val_loss: 0.3122 - val_accuracy: 0.9201\nEpoch 2/20\n157/157 - 89s - loss: 0.0325 - accuracy: 0.9922 - val_loss: 0.3005 - val_accuracy: 0.9425\nEpoch 3/20\n157/157 - 89s - loss: 0.0251 - accuracy: 0.9938 - val_loss: 0.3475 - val_accuracy: 0.9233\nEpoch 4/20\n157/157 - 89s - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.3987 - val_accuracy: 0.9329\nEpoch 5/20\n157/157 - 89s - loss: 0.0175 - accuracy: 0.9938 - val_loss: 0.3592 - val_accuracy: 0.9489\nEpoch 6/20\n157/157 - 89s - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.3309 - val_accuracy: 0.9329\nEpoch 7/20\n157/157 - 89s - loss: 0.0205 - accuracy: 0.9944 - val_loss: 0.4979 - val_accuracy: 0.9169\nEpoch 8/20\n157/157 - 89s - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.4756 - val_accuracy: 0.9265\nEpoch 9/20\n157/157 - 89s - loss: 0.0281 - accuracy: 0.9940 - val_loss: 0.4111 - val_accuracy: 0.9265\nEpoch 10/20\n157/157 - 90s - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.4563 - val_accuracy: 0.9297\nEpoch 11/20\n157/157 - 88s - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.5042 - val_accuracy: 0.9329\nEpoch 12/20\n157/157 - 89s - loss: 0.0120 - accuracy: 0.9978 - val_loss: 0.3402 - val_accuracy: 0.9361\nEpoch 13/20\n157/157 - 89s - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.4586 - val_accuracy: 0.9329\nEpoch 14/20\n157/157 - 89s - loss: 0.0214 - accuracy: 0.9940 - val_loss: 0.4933 - val_accuracy: 0.9201\nEpoch 15/20\n157/157 - 90s - loss: 0.0125 - accuracy: 0.9974 - val_loss: 0.4714 - val_accuracy: 0.9361\nEpoch 16/20\n157/157 - 90s - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.3507 - val_accuracy: 0.9297\nEpoch 17/20\n157/157 - 89s - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.3884 - val_accuracy: 0.9361\nEpoch 18/20\n157/157 - 89s - loss: 0.0137 - accuracy: 0.9984 - val_loss: 0.4644 - val_accuracy: 0.9361\nEpoch 19/20\n157/157 - 89s - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.4004 - val_accuracy: 0.9361\nEpoch 20/20\n157/157 - 89s - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.4778 - val_accuracy: 0.9425\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n  category=CustomMaskWarning)\n","output_type":"stream"},{"name":"stdout","text":"\nAccuracy: 0.9584664536741214\n\nF1 Score is 0.958126913593034\n\nCohen Kappa Score is\n  0.9467282867691341\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data_per = [0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nkappa_score = np.array(list(kappa_score.items())).T[1]\nplt.plot(train_data_per,kappa_score)\nplt.xlabel('Training data in percentage')\nplt.ylabel('Kappa score')\nplt.show()","metadata":{"id":"SvS4GMBFwfkr","execution":{"iopub.status.busy":"2023-01-17T06:30:27.061564Z","iopub.execute_input":"2023-01-17T06:30:27.062464Z","iopub.status.idle":"2023-01-17T06:30:27.267609Z","shell.execute_reply.started":"2023-01-17T06:30:27.062426Z","shell.execute_reply":"2023-01-17T06:30:27.266751Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}